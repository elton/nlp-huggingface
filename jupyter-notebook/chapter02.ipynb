{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace æ¨¡å—è§£è¯»\n",
    "\n",
    "[è§†é¢‘é“¾æ¥](https://www.bilibili.com/video/BV1Dh411c7BQ?p=2&vd_source=0a8068a684645bf59ae78e7f2c9dbcde)\n",
    "\n",
    "## NLP è¦è§£å†³çš„ä»»åŠ¡\n",
    "\n",
    "1. å¤„ç†æ–‡æœ¬æ•°æ®ï¼Œé¦–å…ˆå¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œåˆ†è¯æ“ä½œ(åˆ†è¯çš„æ–¹æ³•å¯èƒ½ä¼šä¸åŒï¼Œä¸­æ–‡å¸¸è§çš„å°±æ˜¯åˆ†è¯æˆ–è€…åˆ†å­—ã€‚\n",
    "2. åˆ†å®Œçš„è¯å®ƒä¸è¿˜æ˜¯å­—ç¬¦å˜›ï¼Œè®¡ç®—æœºè¿˜ä¸è®¤è¯†ï¼Œæœ€ç»ˆæˆ‘ä»¬å¸Œæœ›æŠŠè¿™äº›å­—ç¬¦æ˜ å°„æˆå®é™…çš„ç‰¹å¾(å‘é‡)ã€‚\n",
    "3. è¾“å…¥æå®šå¥½äº†ä¹‹åï¼Œæ¥ä¸‹æ¥å’±ä»¬è¦æ„å»ºæ¨¡å‹äº†(ä¸€èˆ¬éƒ½ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œä¾‹å¦‚ BERT,GPT ç³»åˆ—ç­‰)ã€‚\n",
    "4. æ€ä¹ˆå»å®Œæˆæˆ‘ä»¬è‡ªå·±çš„ä»»åŠ¡å‘¢ï¼ŒåŸºæœ¬ä¸Šå°±æ˜¯åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„åŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒ (è®­ç»ƒæˆ‘ä»¬è‡ªå·±æ•°æ®çš„è¿‡ç¨‹)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åŸºæœ¬æµç¨‹\n",
    "\n",
    "![process](./img/process.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer åˆ†è¯å™¨\n",
    "\n",
    "Tokenizer è¦åšçš„äº‹:\n",
    "\n",
    "* åˆ†è¯ï¼Œåˆ†å­—ä»¥åŠç‰¹æ®Šå­—ç¬¦(èµ·å§‹ï¼Œç»ˆæ­¢ï¼Œé—´éš”ï¼Œåˆ†ç±»ç­‰ç‰¹æ®Šå­—ç¬¦å¯ä»¥è‡ªå·±è®¾è®¡çš„)\n",
    "* å¯¹æ¯ä¸€ä¸ª token æ˜ å°„å¾—åˆ°ä¸€ä¸ª ID (æ¯ä¸ªè¯éƒ½ä¼šå¯¹åº”ä¸€ä¸ªå”¯ä¸€çš„ ID)\n",
    "* è¿˜æœ‰ä¸€äº›è¾…åŠ©ä¿¡æ¯ä¹Ÿå¯ä»¥å¾—åˆ°ï¼Œæ¯”å¦‚å½“å‰è¯å±äºå“ªä¸ªå¥å­(è¿˜æœ‰ä¸€äº› MASKï¼Œè¡¨ç¤ºæ˜¯å¦äº‹åŸæ¥çš„è¯è¿˜æ˜¯ç‰¹æ®Šå­—ç¬¦ç­‰)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer  # è‡ªåŠ¨åˆ¤æ–­ä½¿ç”¨å“ªä¸ªtokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"  # æ ¹æ®æ¨¡å‹åå­—æ¥è‡ªåŠ¨åŠ è½½\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs,\n",
    "                   padding=True,\n",
    "                   truncation=True,\n",
    "                   return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] i've been waiting for a huggingface course my whole life. [SEP]\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> æ‰€æœ‰çš„ç»è¿‡åˆ†è¯å™¨ç¼–ç åçš„æ–‡æœ¬éƒ½æ˜¯ä»¥ ID çš„å½¢å¼å­˜åœ¨çš„ï¼Œè¿™æ ·è®¡ç®—æœºæ‰èƒ½è®¤è¯†ï¼Œæ‰èƒ½è¿›è¡Œåç»­çš„æ“ä½œã€‚\n",
    ">\n",
    "> åˆ†è¯å™¨ç¼–ç çš„ç»“æœåŒ…æ‹¬ï¼š `input_ids` , `attention_mask`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŠ è½½æ¨¡å‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ¨¡å‹è¾“å‡º\n",
    "\n",
    "Transformer æ¨¡å—è¾“å‡ºçš„å‘é‡é€šå¸¸å¾ˆå¤§ã€‚å®ƒä¸€èˆ¬å…·æœ‰ä¸‰ä¸ªç»´åº¦ï¼š\n",
    "\n",
    "* æ‰¹é‡å¤§å°(Batch size)ï¼šä¸€æ¬¡å¤„ç†çš„åºåˆ—æ•°ï¼ˆåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ä¸º `2`ï¼Œå°±æ˜¯ä¸€æ¬¡å¤„ç†ä¸¤ä¸ªå¥å­ï¼‰ã€‚\n",
    "* åºåˆ—é•¿åº¦(Sequence length:)ï¼šåºåˆ—çš„æ•°å­—è¡¨ç¤ºçš„é•¿åº¦ï¼ˆåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ä¸º `16`ï¼Œå°±æ˜¯å¥å­è½¬æ¢ä¸º`input id`åçš„é•¿åº¦ï¼‰ã€‚\n",
    "* éšè—å¤§å°(Hidden size)ï¼šæ¯ä¸ªæ¨¡å‹è¾“å…¥çš„å‘é‡ç»´åº¦ï¼ŒæŠŠ token éƒ½è½¬æ¢æˆå‘é‡ã€‚éšè—å¤§å°å¯ä»¥éå¸¸å¤§ï¼ˆå¯¹äºè¾ƒå°çš„æ¨¡å‹ï¼Œ768 å¾ˆå¸¸è§ï¼Œåœ¨è¾ƒå¤§çš„æ¨¡å‹ä¸­ï¼Œå¯ä»¥è¾¾åˆ° 3072 æˆ–æ›´å¤šï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "# **kwargs çš„å«ä¹‰æ˜¯å°†å­—å…¸æ‰©å±•ä¸ºå…³é”®å­—å‚æ•°è¿›è¡Œä¼ é€’ï¼Œå¦‚æœ kwargs ç­‰äº {'a':1,'b':2,'c':3} ï¼Œé‚£è¿™ä¸ªä»£ç å°±ç­‰ä»·äº test(a=1,b=2,c=3)\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ¨¡å‹åŸºæœ¬é€»è¾‘\n",
    "\n",
    "### æ¨¡å‹å¤´\n",
    "\n",
    "æ¨¡å‹å¤´å°†éšè—çŠ¶æ€çš„é«˜ç»´å‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶æŠ•å½±åˆ°ä¸åŒçš„ç»´åº¦ã€‚å®ƒä»¬é€šå¸¸ç”±ä¸€ä¸ªæˆ–å‡ ä¸ªçº¿æ€§å±‚ç»„æˆï¼š\n",
    "\n",
    "![](./img/002.png)\n",
    "\n",
    "åœ¨æ­¤å›¾ä¸­ï¼Œæ¨¡å‹ç”±å…¶åµŒå…¥å±‚å’Œåç»­å±‚è¡¨ç¤ºã€‚åµŒå…¥å±‚å°†æ ‡è®°åŒ–è¾“å…¥ä¸­çš„æ¯ä¸ªè¾“å…¥ ID è½¬æ¢ä¸ºè¡¨ç¤ºå…³è”æ ‡è®°(token)çš„å‘é‡ã€‚åç»­å±‚ä½¿ç”¨æ³¨æ„æœºåˆ¶æ“çºµè¿™äº›å‘é‡ï¼Œä»¥ç”Ÿæˆå¥å­çš„æœ€ç»ˆè¡¨ç¤ºã€‚\n",
    "\n",
    "ğŸ¤— Transformersä¸­æœ‰è®¸å¤šä¸åŒçš„ä½“ç³»ç»“æ„ï¼Œæ¯ç§ä½“ç³»ç»“æ„éƒ½æ˜¯å›´ç»•å¤„ç†ç‰¹å®šä»»åŠ¡è€Œè®¾è®¡çš„ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªéè¯¦å°½çš„åˆ—è¡¨ï¼š\n",
    "\n",
    "*   `*Model` (retrieve the hidden states)\n",
    "*   `*ForCausalLM`\n",
    "*   `*ForMaskedLM`\n",
    "*   `*ForMultipleChoice`\n",
    "*   `*ForQuestionAnswering`\n",
    "*   `*ForSequenceClassification`\n",
    "*   `*ForTokenClassification`\n",
    "*   ä»¥åŠå…¶ä»– ğŸ¤—\n",
    "\n",
    "å¯¹äºæˆ‘ä»¬çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªå¸¦æœ‰åºåˆ—åˆ†ç±»å¤´çš„æ¨¡å‹ï¼ˆèƒ½å¤Ÿå°†å¥å­åˆ†ç±»ä¸ºè‚¯å®šæˆ–å¦å®šï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å®é™…ä¸Šä¸ä¼šä½¿ç”¨ `AutoModel` ç±»ï¼Œè€Œæ˜¯ä½¿ç”¨ `AutoModelForSequenceClassification` ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ï¼Œå¦‚æœæˆ‘ä»¬è§‚å¯Ÿè¾“å‡ºçš„å½¢çŠ¶ï¼Œç»´åº¦å°†ä½å¾—å¤šï¼šæ¨¡å‹å¤´å°†æˆ‘ä»¬ä¹‹å‰çœ‹åˆ°çš„é«˜ç»´å‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºåŒ…å«ä¸¤ä¸ªå€¼çš„å‘é‡ï¼ˆæ¯ä¸ªæ ‡ç­¾ä¸€ä¸ªï¼‰ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ä¸ºæˆ‘ä»¬åªæœ‰ä¸¤ä¸ªå¥å­å’Œä¸¤ä¸ªæ ‡ç­¾ï¼Œæ‰€ä»¥æˆ‘ä»¬ä»æ¨¡å‹ä¸­å¾—åˆ°çš„ç»“æœæ˜¯2 x 2çš„å½¢çŠ¶ã€‚\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¾“å‡ºåå¤„ç†\n",
    "\n",
    "æˆ‘ä»¬ä»æ¨¡å‹ä¸­å¾—åˆ°çš„è¾“å‡ºå€¼æœ¬èº«å¹¶ä¸ä¸€å®šæœ‰æ„ä¹‰ã€‚æˆ‘ä»¬æ¥çœ‹çœ‹, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬çš„æ¨¡å‹é¢„æµ‹ç¬¬ä¸€å¥ä¸º `[-1.5607, 1.6123]` ï¼Œç¬¬äºŒå¥ä¸º `[ 4.1692, -3.3464]` ã€‚è¿™äº›ä¸æ˜¯æ¦‚ç‡ï¼Œè€Œæ˜¯ _logits_ ï¼Œå³æ¨¡å‹æœ€åä¸€å±‚è¾“å‡ºçš„åŸå§‹éæ ‡å‡†åŒ–åˆ†æ•°ã€‚è¦è½¬æ¢ä¸ºæ¦‚ç‡ï¼Œå®ƒä»¬éœ€è¦ç»è¿‡[SoftMax](https://en.wikipedia.org/wiki/Softmax_function)å±‚ï¼ˆæ‰€æœ‰ğŸ¤—Transformersæ¨¡å‹è¾“å‡ºlogitsï¼Œå› ä¸ºç”¨äºè®­ç»ƒçš„æŸè€—å‡½æ•°é€šå¸¸ä¼šå°†æœ€åçš„æ¿€æ´»å‡½æ•°ï¼ˆå¦‚SoftMaxï¼‰ä¸å®é™…æŸè€—å‡½æ•°ï¼ˆå¦‚äº¤å‰ç†µï¼‰èåˆï¼‰ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5981e-01],\n",
      "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ¨¡å‹é¢„æµ‹ç¬¬ä¸€å¥ä¸º `[0.0402, 0.9598]` ï¼Œç¬¬äºŒå¥ä¸º `[0.9995, 0.0005]` ã€‚è¿™äº›æ˜¯å¯è¯†åˆ«çš„æ¦‚ç‡åˆ†æ•°ã€‚\n",
    "\n",
    "ä¸ºäº†è·å¾—æ¯ä¸ªä½ç½®å¯¹åº”çš„æ ‡ç­¾ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ¨¡å‹é…ç½®çš„ `id2label` å±æ€§ï¼ˆä¸‹ä¸€èŠ‚å°†å¯¹æ­¤è¿›è¡Œè¯¦ç»†ä»‹ç»ï¼‰ï¼š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œè¯¥æ¨¡å‹é¢„æµ‹äº†ä»¥ä¸‹å‡ ç‚¹ï¼š\n",
    "\n",
    "*   ç¬¬ä¸€å¥ï¼šå¦å®šï¼š0.0402ï¼Œè‚¯å®šï¼š0.9598\n",
    "*   ç¬¬äºŒå¥ï¼šå¦å®šï¼š0.9995ï¼Œè‚¯å®šï¼š0.0005\n",
    "\n",
    "æˆ‘ä»¬å·²ç»æˆåŠŸåœ°å¤åˆ¶äº†ç®¡é“çš„ä¸‰ä¸ªæ­¥éª¤ï¼šä½¿ç”¨æ ‡è®°åŒ–å™¨è¿›è¡Œé¢„å¤„ç†ã€é€šè¿‡æ¨¡å‹ä¼ é€’è¾“å…¥ä»¥åŠåå¤„ç†ï¼ç°åœ¨ï¼Œè®©æˆ‘ä»¬èŠ±ä¸€äº›æ—¶é—´æ·±å…¥äº†è§£è¿™äº›æ­¥éª¤ä¸­çš„æ¯ä¸€æ­¥ã€‚\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ¨¡å‹åŸºæœ¬è®­ç»ƒæ–¹æ³•\n",
    "\n",
    "## æ•°æ®é›†ä¸æ¨¡å‹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
